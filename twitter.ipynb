{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb06545f-47b4-482e-b0c1-5c9ffbeec6c8",
   "metadata": {},
   "source": [
    "# Twitter Data Sentiment Analysis\n",
    "\n",
    "In this file we are performing sentiment analysis on the ElonMusk tweet data and performing visualisation on his tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d48d303-0a0b-4070-a21e-b33916eee517",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4612/2696767105.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# tweepy for twitter data requests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmonkeylearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMonkeyLearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tweepy for twitter data requests\n",
    "import tweepy as tw\n",
    "\n",
    "from monkeylearn import MonkeyLearn\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fdef1d-b400-44f8-92a0-526e955a7405",
   "metadata": {},
   "source": [
    "### Loading environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd403b-d543-463c-8886-3778c8f3995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Loading the twitter tokens and keys for twitter OAuth access\n",
    "consumer_key = os.getenv(\"consumer_key\")\n",
    "consumer_secret = os.getenv(\"consumer_secret\")\n",
    "access_token = os.getenv(\"access_token\")\n",
    "access_token_secret = os.getenv(\"access_token_secret\")\n",
    "bearer_token = os.getenv(\"BEARER\")\n",
    "\n",
    "# Loading the monkeylearn api key for sentiment analysis\n",
    "monkeylearn_key = os.getenv(\"monkey_learn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ecad96-a67f-49cf-9093-b41592be83eb",
   "metadata": {},
   "source": [
    "### Twitter api client setup for elonmusk tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5148f-c1b2-4b79-a9f1-4a16d598a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter api client setup for elonmusk tweet\n",
    "query = 'from:elonmusk -is:retweet'\n",
    "client = tw.Client( bearer_token=bearer_token, \n",
    "                        consumer_key=consumer_key, \n",
    "                        consumer_secret=consumer_secret, \n",
    "                        access_token=access_token, \n",
    "                        access_token_secret=access_token_secret, \n",
    "                        return_type = requests.Response,\n",
    "                        wait_on_rate_limit=True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c0d85-1a18-4828-ab89-687bb8e1fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# start time of the data parameter\n",
    "start_time = '2021-01-01T00:00:00Z'\n",
    "\n",
    "# end_time of the data parameter\n",
    "end_time = '2022-05-06T00:00:00Z'\n",
    "\n",
    "userid=\"44196397\"\n",
    "\n",
    "# get maximun 100 tweets for last 7 days only\n",
    "tweets = client.search_recent_tweets(query=query, \n",
    "                                     tweet_fields=['text','author_id', 'created_at'],\n",
    "                                     max_results=100)\n",
    "\n",
    "\n",
    "tweets_dict = tweets.json()\n",
    "tweets_data = tweets_dict['data'] \n",
    "df = pd.json_normalize(tweets_data) \n",
    "\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe9658-2be7-49fa-8576-06bee2a281c4",
   "metadata": {},
   "source": [
    "#### There is a limitation that search_all_tweets in API v2 is not available for the elevated access level. \n",
    "#### It is available only the 'Academic Research' level access has the access to all time data. \n",
    "#### Ignore below failure as we have sourced the dataset from https://www.kaggle.com/datasets/ayhmrba/elon-musk-tweets-2010-2021?select=2021.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe7166-5042-4d75-9a96-ae3478763acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to the limitation on search_recent_tweets trying different api call to fetch full data\n",
    "\n",
    "tweets = client.search_all_tweets(query=query, tweet_fields=['text','author_id', 'created_at'],\n",
    "                                  start_time=start_time,\n",
    "                                  end_time=end_time, \n",
    "                                  max_results=100)\n",
    "\n",
    "# There is a limitation that search_all_tweets in API v2 is not available for the elevated access level. \n",
    "# only the 'Academic Research' level access has the access to all time data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05043cc-7961-4db9-83a7-c8004ecb796a",
   "metadata": {},
   "source": [
    " * Due to the twitter limiation on historical data use the kaggle to fetch the publicly available dataset\n",
    " * https://www.kaggle.com/datasets/ayhmrba/elon-musk-tweets-2010-2021?select=2021.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d417d8-a633-4f0a-9ee6-8db6ff9099a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the tweet data from csv file to dataframe\n",
    "\n",
    "tweet_path = \"Resources/2021_ElonMusk_Tweets.csv\"\n",
    "tweet_df = pd.read_csv( tweet_path, index_col=\"id\", infer_datetime_format=True, parse_dates=True)\n",
    "tweet_df.sort_index()\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a4e44-3ddd-4ff3-a615-02eadae2bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup the data \n",
    "tweet_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d63723-720c-48d0-bf21-c0a4213e8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "tweet_df = tweet_df.dropna().copy()\n",
    "print(\"\\033[1mCLEANED NULLS:\\n\\033[0m\")\n",
    "print( tweet_df.isnull().sum())\n",
    "print(\"\\n\\033[1mCLEANED TWITTER DATA:\\033[0m\\n\")\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c832723-7eb4-452a-bee7-c74a28976c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the tweets that is not bitcoin or crypto related\n",
    "\n",
    "df = tweet_df.loc[tweet_df['tweet'].str.contains(\"bitcoin|crypto\", case=False)]\n",
    "\n",
    "df.to_csv(\"Resources/Filtered_Tweets.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0addd4fe-85d6-4273-a5c9-02ecd624cbbc",
   "metadata": {},
   "source": [
    "##### MonkeyLearn API call to get sentiment analaysis on the tweets against our model \n",
    "##### Model : cl_BT7fBUhn\n",
    "\n",
    "##### Ignore the below code if throws error as we have reached the limit on the monkeylearn. Since we have already sourced the sentiment analysis into a Processed_Tweet.csv file to use it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223a95e3-75b1-44a9-8e74-06eacc25efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the tweet via Monkeylearn modelcl_BT7fBUhn \n",
    "ml = MonkeyLearn(monkeylearn_key)\n",
    "\n",
    "#our sentiment analysis model\n",
    "model_id = 'cl_BT7fBUhn'\n",
    "\n",
    "tweet_classification  = []\n",
    "confidence = []\n",
    "\n",
    "# calling the api with passing tweet column data\n",
    "result = ml.classifiers.classify(model_id, df['tweet'].tolist())\n",
    "\n",
    "#Looping thru the api responce to get the classification data.\n",
    "\n",
    "classifications = result.body\n",
    "\n",
    "for i in classifications:\n",
    "    tweet_classification.append( i['classifications'][0])\n",
    "    confidence.append(i['classifications'][1])\n",
    "\n",
    "#Merging the classification tag to dataframe.\n",
    "df['classification']= tweet_classification\n",
    "df['confidence']=confidence\n",
    "\n",
    "df.head()\n",
    "\n",
    "#saving the sentiment data to csv file to be used in plotting or to be used in other notebooks\n",
    "df.to_csv(\"Resources/Processed_Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e9a4e-f39b-4ab8-a1fb-5b88ac647023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the api call has reached the limit we are using processed sentiment data set \n",
    "tweet_path = \"Resources/Processed_Tweet.csv\"\n",
    "proc_tweet_df = pd.read_csv( tweet_path, index_col=\"id\", infer_datetime_format=True, parse_dates=True)\n",
    "proc_tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d418a-f4da-40f4-9297-e65aee82f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on date and sentiment and keep negative sentitment tweet only\n",
    "\n",
    "proc_tweet_df = proc_tweet_df.sort_values('Classification').drop_duplicates(subset=['date','Classification'], keep='last')\n",
    "\n",
    "proc_tweet_df['date'] = pd.to_datetime(proc_tweet_df['date'],infer_datetime_format=True)\n",
    "proc_tweet_df['period'] = proc_tweet_df['date'].dt.month_name(locale = 'English')\n",
    "proc_tweet_df = proc_tweet_df.set_index('date')\n",
    "\n",
    "# Add more columns to dataframe for each sentiment\n",
    "negative_df = proc_tweet_df.loc[proc_tweet_df['Classification']=='Negative']\n",
    "negative_df['sentiment_numeric'] = -1\n",
    "negative_df['negative'] = 1\n",
    "\n",
    "positive_df = proc_tweet_df.loc[proc_tweet_df['Classification']=='Positive']\n",
    "positive_df['sentiment_numeric'] = 1\n",
    "positive_df['positive'] = 1\n",
    "\n",
    "neutral_df = proc_tweet_df.loc[proc_tweet_df['Classification']=='Neutral']\n",
    "neutral_df['sentiment_numeric'] = 0\n",
    "neutral_df['neutral'] = 1\n",
    "\n",
    "proc_tweet_df = pd.concat([negative_df, positive_df, neutral_df]).sort_values('date')\n",
    "\n",
    "#fill 0 ot NaN values\n",
    "proc_tweet_df = proc_tweet_df.fillna(0).sort_values('date')\n",
    "\n",
    "#store the tweets into csv file for dashboard ploting\n",
    "proc_tweet_df.to_csv(\"Resources/Sentiment_Tweets.csv\")\n",
    "proc_tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffe726-8201-4242-bf26-6cfeb6578e96",
   "metadata": {},
   "source": [
    "#### Plot pie chart by sentiment classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f99ec-0d1d-41ea-9e00-91812ac90665",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot = proc_tweet_df.groupby('Classification').size().plot.pie( autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "\n",
    "pie_plot.legend(\n",
    "          title=\"Classification\",\n",
    "          loc=\"center left\",\n",
    "          bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "pie_plot.set_title(\"Overall Crypto Sentiment\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d775eb-e7d8-4058-af73-884daf7f0e9e",
   "metadata": {},
   "source": [
    "#### Helper methods for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8584331-be8a-4d4f-97a0-da6c2d40e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_chart(data, title, xlabel, ylabel, size):\n",
    "    \"\"\"\n",
    "    Create a line chart based in the data argument.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(6,5))\n",
    "    linechart = data.plot.line(figsize = size, title=title, legend=True )\n",
    "    linechart.set_xlabel(xlabel)\n",
    "    linechart.set_ylabel(ylabel)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "# Resuable function for creating bar chart\n",
    "def create_bar_chart(data, title, xlabel, ylabel,  size):\n",
    "    \"\"\"\n",
    "    Create a barplot based in the data argument.\n",
    "    \"\"\"\n",
    "  \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(6,6))\n",
    "    barchart = data.plot.bar(figsize=size, title=title, x=xlabel )\n",
    "    barchart.set_xlabel(xlabel)\n",
    "    barchart.set_ylabel(ylabel)\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd0365-7bcb-469e-9fd4-ab4887f9490a",
   "metadata": {},
   "source": [
    "#### Visualize the tweet activity by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd221e6-6d71-4e07-92f2-dc08d8314cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reseting index to use date column\n",
    "proc_tweet_df = proc_tweet_df.reset_index()\n",
    "\n",
    "create_bar_chart(proc_tweet_df[[\"date\",\"replies_count\",\"retweets_count\",\"likes_count\"]], \"Tweet activity by Date\", 'date', 'retweets_count',  (20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bb87d-08eb-478b-b555-d49a43c5d822",
   "metadata": {},
   "source": [
    "#### Visualize the tweet activity by sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cb462-312d-4159-928a-221ab5ab7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby the tweet columns by classification\n",
    "groupby_classification = proc_tweet_df[[\"replies_count\",\"retweets_count\",\"likes_count\"]].groupby(proc_tweet_df.Classification).sum().reset_index()\n",
    "\n",
    "create_bar_chart(groupby_classification, \"Sum of tweet activity per Sentiment\", 'Classification', 'retweets_count',  (6,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eecb54-3bec-4532-b218-02eff1925c98",
   "metadata": {},
   "source": [
    "#### Visualize the sentiment by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797f88f-5796-47f2-831d-55e1ff88315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the sentiments by period:month\n",
    "groupby_period = proc_tweet_df[[\"negative\",\"positive\",\"neutral\"]].groupby(proc_tweet_df.period).sum().reset_index()\n",
    "\n",
    "# Sort by month index\n",
    "sort_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July','September', 'October', 'November','December']\n",
    "\n",
    "groupby_period.index = pd.CategoricalIndex(groupby_period['period'], categories=sort_order, ordered =True)\n",
    "groupby_period =groupby_period .sort_index()\n",
    "\n",
    "#Visualize the sentiment by month\n",
    "create_line_chart(groupby_period, \"Sentiment count by Month\", 'Period', 'Tweets',  (10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f852e7-5df9-430a-ae37-b3e731f18228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
